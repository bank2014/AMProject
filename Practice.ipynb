{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5e31f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===처리 전======================================\n",
      "0    M\n",
      "1    M\n",
      "2    F\n",
      "Name: Gender, dtype: object\n",
      "===처리 후========================================\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "[array(['F', 'I', 'M'], dtype=object)]\n",
      "===처리된 train set==================================\n",
      "[[ 0.      0.      1.      0.57    0.48    0.18    0.9395  0.399   0.2\n",
      "   0.295  14.    ]\n",
      " [ 0.      0.      1.      0.56    0.425   0.135   0.9415  0.509   0.2015\n",
      "   0.1975  9.    ]\n",
      " [ 1.      0.      0.      0.655   0.51    0.15    1.043   0.4795  0.223\n",
      "   0.305   9.    ]]\n",
      "====train set을 y_train과 x_train으로 분리============================\n",
      "[14.  9.  9. ...  6. 10. 10.]\n",
      "[[0.     0.     1.     ... 0.399  0.2    0.295 ]\n",
      " [0.     0.     1.     ... 0.509  0.2015 0.1975]\n",
      " [1.     0.     0.     ... 0.4795 0.223  0.305 ]\n",
      " ...\n",
      " [0.     1.     0.     ... 0.363  0.1925 0.2515]\n",
      " [1.     0.     0.     ... 0.465  0.2055 0.2765]\n",
      " [0.     1.     0.     ... 0.7735 0.4405 0.655 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# EDA에서 했지만 다시 받아온다\n",
    "train_raw = pd.read_csv('./train2.csv')\n",
    "test_raw = pd.read_csv('./test2.csv')\n",
    "\n",
    "train = train_raw.drop(columns = ['id','Unnamed: 0']) # id 제거\n",
    "test = test_raw.drop(columns = ['id','Unnamed: 0'])\n",
    "\n",
    "print('===처리 전======================================') # Gender one-hot encoding 처리 전\n",
    "\n",
    "print(train['Gender'][:3])\n",
    "\n",
    "print('===처리 후========================================')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_only_Gender = train[['Gender']]\n",
    "onehot_encoder = OneHotEncoder()\n",
    "train_onehot_Gender = onehot_encoder.fit_transform(train_only_Gender)\n",
    "\n",
    "print(train_onehot_Gender.toarray()[:3])\n",
    "print(onehot_encoder.categories_)\n",
    "\n",
    "print('===처리된 train set==================================')\n",
    "\n",
    "train_noGender = train.drop(('Gender'), axis=1)\n",
    "train_noGender_np = train_noGender\n",
    "train = np.c_[train_onehot_Gender.toarray(), train_noGender_np]\n",
    "print(train[:3])\n",
    "\n",
    "print('====train set을 y_train과 x_train으로 분리============================')\n",
    "y_train = np.array(train).T[-1] # Target만 추출한 것: y_data\n",
    "print(y_train)\n",
    "\n",
    "x_train = pd.DataFrame(train).drop(10,axis=1) # Target 이외의 데이터: x_data\n",
    "x_train = np.array(x_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad38166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu'), # 확률이나 bool 은 출력노드 1개 - 추천: sigmoid는 0~1 사이 값\n",
    "])\n",
    "\n",
    "# 확률 예측에 좋은 loss함수: binary_crossentropy -> 0~1 결과인 분류/확률 문제에서 씀\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e810a746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 3ms/step - loss: 46.0605 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 8.7613 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 7.0763 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.8501 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.7165 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3849 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.3253 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 6.0372 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.9566 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.7630 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5503 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.5137 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4163 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4036 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1708 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1982 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1648 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3186 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3366 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0455 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0082 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.3127 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0861 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9872 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8926 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.1528 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0312 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.4463 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8618 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8879 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9092 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0306 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8467 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8073 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0618 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0253 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8009 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9644 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8645 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9896 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8207 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7793 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8463 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8497 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8261 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8970 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8616 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9776 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7921 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8414 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7395 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9654 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0793 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8442 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8476 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.6191 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8824 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0797 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8759 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7863 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9546 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7094 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8222 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8422 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6972 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7867 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8261 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.2169 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6297 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6619 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7501 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8007 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7668 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6225 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6080 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.8404 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6916 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7886 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9195 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6319 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6531 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6692 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7108 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7013 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9966 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7987 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6924 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7134 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6977 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6476 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9484 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7757 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7967 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 5.0155 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.9367 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6301 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.5278 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.6256 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7018 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7133 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5feb7cf40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with tf.device(\"/device:GPU:0\"):\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e137d353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2019076021_김선우.model\\assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.save('2019076021_김선우.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. 모델 학습시키기\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f82dbe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m SVG(\u001b[43mmodel_to_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m(prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "976799da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
